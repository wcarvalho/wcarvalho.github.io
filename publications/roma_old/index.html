<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  
  <meta property="og:image" content="/img/abstract_head.png">
  <meta property="og:image:type" content="image/png">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Reinforcement Learning for Sparse-Reward Object-Interaction Tasks in First-person Simulated 3D Environments &middot; Wilka Carvalho
    
  </title>

  <!-- CSS -->

  <link rel="stylesheet" href="/public/css/projects.css">
  <link rel="stylesheet" href="/public/css/icons.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
  <link rel="stylesheet" href="/public/css/general.css">


  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/img/brain-icon.png">
  <link rel="shortcut icon" href="/img/brain-icon.png">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>

  <!-- Math Support -->

  <body class="layout">

      <div class="masthead">
    
  <div class="top-left">
  </div>
  <div class="bottom-right">
    <div class="container">
      <div align="center">
        <h3 class="masthead-title">
            <img class="nsf responsive-img" src="/img/headshot.jpg"> <br>
            <a href="/" title="Home">Wilka Carvalho</a><br>
            <small>Aspiring Cognitive Scientist</small>
        </h3>
      </div>
    </div>
  </div>
  <div class="bottom-left">
    <div class="container">
      <a href="https://twitter.com/CogSciKid/"><i class="svg-icon twitter"></i></a>
      <a href="https://github.com/wcarvalho/"><i class="svg-icon github"></i></a>
      <a href="https://www.linkedin.com/in/wilkacarvalho/"><i class="svg-icon linkedin"></i></a>
      <a href="mailto:wcarvalho92@gmail.com"><i class="svg-icon email"></i></a>
    </div>
  </div>
</div>
      <div class="navbar-outter">
<nav class="navbar sticky-top justify-content-between navbar-expand-sm navbar-nav navbar-dark bg-dark">
<!-- <div class="navbar-inner"> -->
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNavDropdown">
    <ul class="navbar-nav mr-auto">
      <li class="nav-item active">
        <!-- <a href="/">Home</a> -->
        <a class="nav-link" href="/#">Home <span class="sr-only">(current)</span></a>
      </li>


      <li class="nav-item">
        <a class="nav-link" href="/main-pages/publications">Publications</a>
      </li>

      <li class="nav-item">
        <a class="nav-link" href="/main-pages/press">Press</a>
      </li>

      <li class="nav-item dropdown">
        <a class="nav-link dropdown-toggle" href="/main-pages/projects/" id="navbarDropdownMenuLink">
          Side Projects
        </a>
        <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
          <a class="dropdown-item" href="/main-pages/projects/" id="navbarDropdownMenuLink">
          Projects
          </a>
          <a class="dropdown-item" href="/main-pages/projects/#essays">Essays</a>
          <a class="dropdown-item" href="/main-pages/projects/#poetry">Poetry</a>
        </div>
      </li>

      <li class="nav-item">
        <a class="nav-link" href="/files/wilka_carvalho_CV.pdf">CV</a>
      </li>

      <li class="nav-item">
        <a class="nav-link" href="/misc/acknowledgments">Acknowledgements</a>
      </li>
    </ul>



    <ul class="navbar-nav navbar-right">
      <li class="nav-item dropdown navbar-right">
        <a class="nav-link dropdown-toggle" href="" id="navbarDropdownMenuLink">
          Learning Resources
        </a>
        <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
          <a class="dropdown-item" href="https://wcarvalho.github.io/Phd-Resources/" id="navbarDropdownMenuLink">
          PhD Resources
          </a>
          <a class="dropdown-item" href="https://wcarvalho.github.io/ML-Brain-Resources/">ML/Brain Resources</a>
          <a class="dropdown-item" href="/misc/books">Useful Books</a>
        </div>
      </li>

      <li class="nav-item navbar-nav navbar-right">
        <a class="nav-link"  href="/main-pages/blog">Blog</a>
      </li>
    </ul>

</div>
<!-- </div> -->
</nav>
</div>
      <div class="container content ">
        <div class="post">
  <center>
    <h2 class="post-title">Reinforcement Learning for Sparse-Reward Object-Interaction Tasks in First-person Simulated 3D Environments</h2>
  </center>
  <span class="post-date">
    
  </span>
  <br><br>
<center>
<div class="container">

  <div class="row">
    <div class="col">
      <a href="/"><span style="color: #9f30a5">Wilka Carvalho</span></a><sup>1</sup>&emsp;
      <a href="https://aliang8.github.io/">Anthony Liang</a><sup>1</sup>&emsp;
      <a href="https://sites.google.com/view/kiminlee">Kimin Lee</a><sup>3</sup>&emsp;
      <a href="https://sites.google.com/view/sungryull">Sungryull Sohn</a><sup>1</sup>
    </div>
  </div>


  <div class="row">
    <div class="col">
      <a href="https://web.eecs.umich.edu/~honglak/">Honglak Lee</a><sup>1,4</sup>&emsp;
      <a href="http://www-personal.umich.edu/~rickl/">Richard L. Lewis</a><sup>2</sup>&emsp;
      <a href="https://web.eecs.umich.edu/~baveja/">Satinder Singh</a><sup>1,5</sup>
    </div>
  </div>

  <div class="row">
    <div class="col">
      <sup>1</sup>University of Michigan, Dept. of Computer Science
    </div>
  </div>

  <div class="row">
    <div class="col">
      <sup>2</sup>University of Michigan, Dept. of Psychology
    </div>
  </div>

  <div class="row">
    <div class="col">
      <sup>3</sup>UC Berkeley&emsp;<sup>4</sup>Google Brain&emsp;<sup>5</sup>DeepMind
    </div>
  </div>

</div>
</center>

<br><br>






<br>
<center>
  <div class="embed-responsive embed-responsive-16by9">
  <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/E8xqlK8cuKw" allowfullscreen></iframe>
  </div>
</center>
<!-- <center><img class="responsive-img" style="max-width: 750" src="/files/publications/roma/architecture.png"></center>
 -->
<br>
<!-- <h1>Abstract</h1> -->
Sequential decision-making tasks that require relating and using multiple novel objects pose significant sample-efficiency challenges for agents learning from sparse task rewards. In this work, we begin to address these challenges by leveraging an agent's object-interactions to define an auxilliary task that enables sample-efficient reinforcement learning (RL) of such tasks. To accomplish this, we formulate ROMA: a relational reinforcement learning agent that learns an object-centric forward model during task learning. We find that this enables it to learn object-interaction tasks much faster than other relational RL agents with alternative auxiliary tasks for driving good object-representation learning.  In order to evaluate the performance of our agent, we introduce a set of object-interaction tasks in the AI2Thor virtual home environment that require relating and interacting with multiple objects.  By comparing against an agent equipped with ground-truth object-information, we find that learning an object-centric forward model best closes the performance gap, achieving $\geq 80\%$ of its sample-efficiency on $7$ out of $8$ tasks, with the next best method doing so on $3$ out of $8$ tasks. Additionally, we find that our object-model best captures interesting object information such as category, specific object state, and relationships among objects.

<br><br>
<div class="row">
<div class="row pub-links">
  <p>
    <!-- <a href="/publications/roma"> <button type = "button" class = "btn btn-primary"> Blog </button></a> -->
    <a href="/files/publications/roma/roma.pdf"> <button type = "button" class = "btn btn-primary"> Paper </button></a>
    <a href="https://twimlai.com/relational-object-centric-agents-for-completing-simulated-household-tasks-with-wilka-carvalho/">
        <button type = "button" class = "btn btn-primary">
        Podcast
        </button>
    </a>
  </p>
</div>
</div>

<br><br><br><br>
<hr>
<br>
<center>
  <h1>Relational, Object-Model Learning Agent</h1>
</center>
When deciding to interact with an object, our agent uses self-attention to attend to other objects so it can incorporate relationships among objects into its decision making. Afterward, it predicts the consequnces of its object-interaction, factoring in the object relationships it computed via self-attention. This provides a dense learning signal for learning about objects and their relationships prior to experiencing task reward.
<center>
  <img class="responsive-img" style="max-width: 300" src="/files/publications/roma/overview.png">
</center>


<br><br><br>
<hr>
<br>
<center>
  <h1>Object-Centric Decision Making</h1>
</center>
<center>
  <img class="responsive-img" style="max-width: 300" src="/files/publications/roma/architecture.png">
</center>
A scene is broken down into object-image-patches $\{o_j\}$ (e.g. of a pot, potato, and stove knob). The scene image is combined with the agent's location to define the <i>context</i> of the objects, $s^\kappa$. The objects  $\{o_j\}$ and their context $s^\kappa$ are processed by different encoding branches and then recombined by a relational module $\mathcal{R}$ that uses self-attention to produce inputs for computing Q-value estimates. Here, $\mathcal{R}$ might select the pot image-patch when computing Q-values for interacting with the stove-knob image-patch. Actions are selected as (object-image-patch, base action) pairs $a=(o_c, b)$. The agent then predicts the consequences of its interactions with our relational object-model $f_{\tt model}$.




<br><br><br>
<hr>
<br>
<center>
  <h1>Results</h1>
</center>
<h3>A basic object level understanding isn't sufficient for our challenging tasks</h3>
It is well-known that providing an object-level understanding improves performance and sample-efficiency. Despite, below we see that supplying DQN with a basic object-level understanding via object-image-patches or object-ids is insufficient to learn challenging tasks that require reasoning over multiple objects and the object-state they occupy. We hypothesize that this is due to the large-branching factor induced by object-interactions and the sparse-reward learning signal (random policies complete tasks $\approx 10\times$ in 500K samples).
<center>
  <img class="responsive-img" style="max-width: 300" src="/files/publications/roma/ablation.png">
</center>
<h3>The key is combining a relational object-centric policy (Relational Object-DQN) with a Relational Object-Model</h3>
Interestingly, despite facing a sparse-reward problem, we find that with a basic $\epsilon$-greedy exploration strategy, simply adding object-attention to an object-centric DQN (Relational Object-DQN, grey curve in Figure below) enables progress towards efficient learning. Somewhat surprisingly, we find that adding rich hand-designed object-representations (Relational Object-DQN + Ground-Truth Object-Information, black curve in Figure below) enables learning of all the tasks we study. <b>This indicates that we can efficiently learn from only a few rewarding instances with a good object-centric inductive bias</b>. 
<br>
<br>
<center>
  <img class="responsive-img" style="max-width: 300" src="/files/publications/roma/lower-upper.png">
</center>
<br>
We find that adding a strong unsupervised object-representation learning method to our Relational Object-DQN such as OCN or COBRA's non-relational object-model helps but is insufficient. However, adding our <i>Relational</i> Object-Model enables $\geq 75\%$ ground-truth sample-efficiency on $7/8$ tasks. Thus, the key to sample-efficient learning is bootstraping learning of both object-representations <b>and</b> their relations.
<br><br>
<center>
  <img class="responsive-img" style="max-width: 300" src="/files/publications/roma/auc.png">
</center>
<!-- <br>
Additionally, we find that our relational object-model best captures interesting object information such as category, specific object state, and relationships among objects.
<center>
  <img class="responsive-img" style="max-width: 300" src="/files/publications/roma/table.png">
</center> -->
</div>

      </div>

    <!-- jquery -->
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>

<!-- bootstrap -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>

<!-- popper -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>


<script type="text/javascript" src="/public/js/materialize.min.js"></script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>


<!--  -->

<!-- Bootstrap core JavaScript -->
<!-- <script src="/public/vendor/jquery/jquery.min.js"></script> -->
<!-- <script src="/public/vendor/popper/popper.min.js"></script> -->
<!-- <script src="/public/vendor/bootstrap/js/bootstrap.min.js"></script> -->

<!-- Plugin JavaScript -->
<!-- <script src="/public/vendor/jquery-easing/jquery.easing.min.js"></script> -->

<!-- Contact form JavaScript -->
<!-- <script src="/public/js/jqBootstrapValidation.js"></script> -->
<!-- <script src="/public/js/contact_me.js"></script> -->

<!-- Custom scripts for this template -->
<!-- <script src="/public/js/agency.min.js"></script> -->

<!-- Materialize -->
<!-- <script src="/public/js/materialize.min.js"></script> -->
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [ ['$','$'] ],
      displayMath: [ ['$$','$$'] ],
      processEscapes: true,
    }
  });
</script>
<script type="text/javascript"
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-72232702-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-72232702-1');
</script>

  </body>
</html>