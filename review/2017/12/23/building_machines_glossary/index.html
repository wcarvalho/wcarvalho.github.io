<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  
  <meta property="og:image" content="/img/abstract_head.png">
  <meta property="og:image:type" content="image/png">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Building Machines that Learn and Think Like People (Glossary) &middot; Wilka Carvalho
    
  </title>

  <!-- CSS -->

  <link rel="stylesheet" href="/public/css/projects.css">
  <link rel="stylesheet" href="/public/css/icons.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
  <link rel="stylesheet" href="/public/css/general.css">


  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/img/brain-icon.png">
  <link rel="shortcut icon" href="/img/brain-icon.png">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>

  <!-- Math Support -->

  <body class="layout">

      <div class="masthead">
    
  <div class="top-left">
  </div>
  <div class="bottom-right">
    <div class="container">
      <div align="center">
        <h3 class="masthead-title">
            <img class="nsf responsive-img" src="/img/headshot.jpg"> <br>
            <a href="/" title="Home">Wilka Carvalho</a><br>
            <small>Aspiring Cognitive Scientist</small>
        </h3>
      </div>
    </div>
  </div>
  <div class="bottom-left">
    <div class="container">
      <a href="https://twitter.com/CogSciKid/"><i class="svg-icon twitter"></i></a>
      <a href="https://github.com/wcarvalho/"><i class="svg-icon github"></i></a>
      <a href="https://www.linkedin.com/in/wilkacarvalho/"><i class="svg-icon linkedin"></i></a>
      <a href="mailto:wcarvalho92@gmail.com"><i class="svg-icon email"></i></a>
    </div>
  </div>
</div>
      <div class="navbar-outter">
<nav class="navbar sticky-top justify-content-between navbar-expand-sm navbar-nav navbar-dark bg-dark">
<!-- <div class="navbar-inner"> -->
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNavDropdown">
    <ul class="navbar-nav mr-auto">
      <li class="nav-item active">
        <!-- <a href="/">Home</a> -->
        <a class="nav-link" href="/#">Home <span class="sr-only">(current)</span></a>
      </li>


      <li class="nav-item">
        <a class="nav-link" href="/main-pages/publications">Publications</a>
      </li>

      <li class="nav-item">
        <a class="nav-link" href="/main-pages/press">Press</a>
      </li>

      <li class="nav-item dropdown">
        <a class="nav-link dropdown-toggle" href="/main-pages/projects/" id="navbarDropdownMenuLink">
          Side Projects
        </a>
        <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
          <a class="dropdown-item" href="/main-pages/projects/" id="navbarDropdownMenuLink">
          Projects
          </a>
          <a class="dropdown-item" href="/main-pages/projects/#essays">Essays</a>
          <a class="dropdown-item" href="/main-pages/projects/#poetry">Poetry</a>
        </div>
      </li>

      <li class="nav-item">
        <a class="nav-link" href="/files/wilka_carvalho_CV.pdf">CV</a>
      </li>

      <li class="nav-item">
        <a class="nav-link" href="/misc/acknowledgments">Acknowledgements</a>
      </li>
    </ul>



    <ul class="navbar-nav navbar-right">
      <li class="nav-item dropdown navbar-right">
        <a class="nav-link dropdown-toggle" href="" id="navbarDropdownMenuLink">
          Learning Resources
        </a>
        <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
          <a class="dropdown-item" href="https://wcarvalho.github.io/Phd-Resources/" id="navbarDropdownMenuLink">
          PhD Resources
          </a>
          <a class="dropdown-item" href="https://wcarvalho.github.io/ML-Brain-Resources/">ML/Brain Resources</a>
          <a class="dropdown-item" href="/misc/books">Useful Books</a>
        </div>
      </li>

      <li class="nav-item navbar-nav navbar-right">
        <a class="nav-link"  href="/main-pages/blog">Blog</a>
      </li>
    </ul>

</div>
<!-- </div> -->
</nav>
</div>
      <div class="container content ">
        <div class="post">
  <h2 class="post-title">Building Machines that Learn and Think Like People (Glossary)</h2>
  <span class="post-date">
    23 Dec 2017
    
     | <cite> review </cite>
    
    
    <br>
    <em>
      tags: cognitive-science, machine-learning, brain, deep-learning
    </em>
    
  </span>
  
    Note: Ideas and opinions that are my own and not of the article will be in an <font color="grey"><em>italicized grey</em></font>.<br><br>

<h1>Series Table of Contents</h1>

<a href="/review/2017/12/23/building_machines_intro">Part 1: Introduction and History</a> <br>
<a href="/review/2017/12/31/building_machines_challenges">Part 2: Challenges for Building Human-Like Machines</a> <br>
<a href="/review/2018/01/01/building_machines_developmental">Part 3: Developmental Software</a> <br>
<a href="/review/2018/01/06/building_machines_learning">Part 4: Learning as Rapid Model-Building</a> <br>
<a href="/review/2018/01/06/building_machines_thinking">Part 5: Thinking Fast</a> <br>
<a href="/review/2017/12/23/building_machines_resources">Resources</a> <br>
<a href="/review/2017/12/23/building_machines_glossary">Glossary</a> <br>

<p><br /></p>

<table>
  <thead>
    <tr>
      <th>Article Table of Contents</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="#deep-learning">Deep Learning, Neural Networks, Artificial Neural Networks</a></td>
    </tr>
    <tr>
      <td><a href="#causal-models">Causal Models</a></td>
    </tr>
    <tr>
      <td><a href="#inference">Inference</a></td>
    </tr>
    <tr>
      <td><a href="#model-free-model-based">Model-free, Model-based</a></td>
    </tr>
    <tr>
      <td><a href="#symbolic-representations">Symbolic representations</a></td>
    </tr>
    <tr>
      <td><a href="#sub-symbolic-representations">Sub-symbolic representations</a></td>
    </tr>
    <tr>
      <td><a href="#distributed-representations">Distributed Representations</a></td>
    </tr>
    <tr>
      <td><a href="#inductive-biases">Inductive Biases</a></td>
    </tr>
    <tr>
      <td><a href="#compositionality">Compositionality</a></td>
    </tr>
    <tr>
      <td><a href="#learning-to-learn">Learning-to-learn</a></td>
    </tr>
    <tr>
      <td><a href="#generative-models">Generative Models</a></td>
    </tr>
  </tbody>
</table>

<h2 id="deep-learning">Deep Learning</h2>
<p><strong>Also Neural Networks, Artificial Neural Networks</strong><br />
A model vaguely resembling a biological neural network that learns how to map inputs to outputs. For example, suppose you give it images of cats and dogs as inputs and the labels “cat” and “dog”, respectively. It will learn to predict the label “cat” when given cat images and “dog” when given dog images.</p>

<p><img src="https://mapr.com/blog/demystifying-ai-ml-dl/assets/process.png" alt="deep_learning" /></p>

<p>Also, I use “Neural Networks”, “Artificial Neural Networks”, and “Deep Learning” interchangeably. They all refer to artificial neural networks. When referring to the brain’s networks, I say “biological neural networks”.</p>

<h2 id="causal-models">Causal Models</h2>
<p>Causal models attempt to abstractly describe the real world process that produces an observation. For example, the model below represents drawing characters as combining strokes of a pen in a particular sequence.</p>

<p><img src="/files/posts/building_machines_like_people/bpl.png" alt="bpl" /></p>

<h2 id="generative-models">Generative models</h2>
<p>Generative models attempt to describe a process for generating data. However, unlike <a href="#causal-models">causal models</a>, they do not attempt to model the real world process that generated the data. In the example of characters above, it would be sufficient if a generative model simply learned to predict the pixels associated with a character and not the strokes that might have produced it.</p>

<h2 id="inference">Inference</h2>
<p>When A typically causes B, you can predict that B will come from A, and you can do <em>inference</em> that A was the <strong>cause</strong> of B. For example if A=”its raining” and B=”Bob wears boots”. You might see that it’s raining and <strong>predict</strong> Bob will be wearing boots or you might see that Bob is wearing boots and <strong>infer</strong> its probably raining.</p>

<p><img src="/files/posts/building_machines_like_people/inference.png" alt="inference" /></p>

<h2 id="model-free-model-based">Model-free, Model-based</h2>
<p>Model-free algorithms use experience to directly learn quantities while model-based algorithms learn models for the world (such as probabilities for transitioning between world states). For example, learning an internal geographical map to get to work is “model-based”, whereas simply learning what turn to make at each corner but not remembering where each turn takes you is “model-free”. Model-based is somewhat preferred because you can use your learned map to plan a new way to get to work that is a <em>composition</em> of your previous routes.</p>

<h2 id="symbolic-representations">Symbolic representations</h2>
<p>Symbols can be thought of as variables that represent different quantities. For example, every letter of the alphabet can be seen as a symbol. Likewise, words in our vocabulary.</p>

<h2 id="sub-symbolic-representations">Sub-symbolic representations</h2>
<p>A representation is sub-symbolic if its constituents are not symbolic. For example, you could represent words as points in space like in the example below. Here, each constituent of the word is a real number (an x or y coordinate). This differs from a symbolic representation which would represent the words as symbols in and of themselves.</p>

<p><img src="http://suriyadeepan.github.io/img/seq2seq/we1.png" alt="word2vec" /></p>

<h2 id="distributed-representations">Distributed Representations</h2>
<p>A distributed representation is one where different computational units hold different parts of a representation. In the example of neurons in a neural network, every neuron in a layer might by itself hold one aspect of a representation you care about. For example, in the plot above words are represented by 2 coordinates (x and y). Here, each neuron could hold the value for one coordinate (one neuron for x, the other for y), so the representation for the word is distributed <strong>across</strong> the neurons.</p>

<h2 id="inductive-biases">Inductive Biases</h2>
<p>Inductive Biases are the assumptions your model makes about the relationship between its inputs and outputs for <strong>new, unseen</strong> inputs. For example, a model that learns to represent visual concepts might have the inductive bias that objects are composed of learnable parts and relations. With the example of the segway below, it could be decomposed into two wheels connected by a platform, which provides the base for a post, which holds the handlebars, etc.</p>

<p><img height="200px" src="/files/posts/building_machines_like_people/segway.png" /></p>

<h2 id="compositionality">Compositionality</h2>
<p>Compositionality is the classic idea that new representations can be constructed through combinations of primitive elements. Real world examples include sentences which are combinations of words, the “primitives” of language, or programs which are compositions of functions, which are themselves compositions of more primitive data types.</p>

<h2 id="learning-to-learn">Learning-to-learn</h2>
<p>Learning-to-learn is the idea of using learned concepts as “primitives” for other concepts when learning. In the example of the segway above, you identify a segway more quickly by re-using the concepts you’ve already learned for wheels, platforms, posts, etc.</p>


<h3>Thank you for reading. Please leave any comments or thoughts below or, alternatively, feel free to email me at <a href="mailto:wcarvalho92@gmail.com">wcarvalho92@gmail.com</a>.</h3>

  
</div>

<h2>Related Posts</h2>





<ol>


    
    

    

<!--      -->

    
    <li>
        <div>
        <h5><a href="/commentary/2018/01/29/learning_quickly/">The Pitfalls of Learning Quickly</a> - January 29, 2018 |  <span class="label label-default">cognitive-science</span> </h5>
        </div>
        
        
    </li>
    



    
    

    

<!--      -->

    
    <li>
        <div>
        <h5><a href="/review/2018/01/06/building_machines_thinking/">Building Machines that Learn and Think Like People (pt 5. Thinking Fast)</a> - January 06, 2018 |  <span class="label label-default">cognitive-science</span>  <span class="label label-default">machine-learning</span>  <span class="label label-default">brain</span>  <span class="label label-default">deep-learning</span> </h5>
        </div>
        
        
    </li>
    



    
    

    

<!--      -->

    
    <li>
        <div>
        <h5><a href="/review/2018/01/06/building_machines_learning/">Building Machines that Learn and Think Like People (pt 4. Learning as Rapid Model-Building)</a> - January 06, 2018 |  <span class="label label-default">cognitive-science</span>  <span class="label label-default">machine-learning</span>  <span class="label label-default">brain</span>  <span class="label label-default">deep-learning</span> </h5>
        </div>
        
        
            
</ol>


  
<div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_shortname  = 'wilkacarvalho';
  var disqus_identifier = '/review/2017/12/23/building_machines_glossary/';

  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



      </div>

    <!-- jquery -->
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>

<!-- bootstrap -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>

<!-- popper -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>


<script type="text/javascript" src="/public/js/materialize.min.js"></script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>


<!--  -->

<!-- Bootstrap core JavaScript -->
<!-- <script src="/public/vendor/jquery/jquery.min.js"></script> -->
<!-- <script src="/public/vendor/popper/popper.min.js"></script> -->
<!-- <script src="/public/vendor/bootstrap/js/bootstrap.min.js"></script> -->

<!-- Plugin JavaScript -->
<!-- <script src="/public/vendor/jquery-easing/jquery.easing.min.js"></script> -->

<!-- Contact form JavaScript -->
<!-- <script src="/public/js/jqBootstrapValidation.js"></script> -->
<!-- <script src="/public/js/contact_me.js"></script> -->

<!-- Custom scripts for this template -->
<!-- <script src="/public/js/agency.min.js"></script> -->

<!-- Materialize -->
<!-- <script src="/public/js/materialize.min.js"></script> -->
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [ ['$','$'] ],
      displayMath: [ ['$$','$$'] ],
      processEscapes: true,
    }
  });
</script>
<script type="text/javascript"
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-72232702-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-72232702-1');
</script>

  </body>
</html>